#! /usr/bin/ruby1.9.1
#-*- encoding: utf-8 -*-
#
# Description: Tokenize Turkish input into wordlists
# Author:      Tobias Koch <tobias.koch@gmail.com>
# License:     Public Domain
#

INSTALL_DIR = File.expand_path(File.dirname(File.symlink?(__FILE__) ?
  File.readlink(__FILE__) : __FILE__) + '/..')
$LOAD_PATH.unshift INSTALL_DIR + '/lib'

TOKENIZER_VERSION = "0.0.1"

TOKENIZER_SUCCESS          = 0
TOKENIZER_ERROR_INVOCATION = 1
TOKENIZER_ERROR_RUNTIME    = 2

TOKENIZER_EXECUTABLE_NAME = 'vikisubex'

require 'getoptlong'
require 'tokenize'


def usage
  $stderr.write "TR Language Tools Tokenizer, version #{TOKENIZER_VERSION}                        \n"
  $stderr.write "Copyright 2012, Tobias Koch <tobias.koch@gmail.com>                              \n"
  $stderr.write "                                                                                 \n"
  $stderr.write "tokenize [OPTIONS] <files|stdin>                                                 \n"
  $stderr.write "                                                                                 \n"
  $stderr.write "OPTIONS:                                                                         \n"
  $stderr.write " --help, -h            Print this help text and exit                             \n"
  $stderr.write " --sort, -s            Sort the output                                           \n"
  $stderr.write " --unique, -u          Remove duplicates from output                             \n"
  $stderr.write "                                                                                 \n"
end


def parse_cmd_line
  params = {
    :sort => false,
    :unique => false
  }

  opts = GetoptLong.new(
    ['--help', '-h', GetoptLong::NO_ARGUMENT ],
    ['--sort', '-s', GetoptLong::NO_ARGUMENT ],
    ['--unique', '-u', GetoptLong::NO_ARGUMENT ]
  )

  begin
    opts.quiet = true
    opts.each do |opt, arg|
      case opt
        when '--help'
          usage
          exit TOKENIZER_SUCCESS
        when '--unique'
          params[:unique] = true
        when '--sort'
          params[:sort] = true
        else
      end
    end
  rescue GetoptLong::InvalidOption => e
    $stderr.write "#{TOKENIZER_EXECUTABLE_NAME}: #{e.message}\n"
    exit TOKENIZER_ERROR_INVOCATION
  end

  return params
end


begin # main()

  params = parse_cmd_line
  tokenizer = Tokenizer.new(params)

  if params[:sort] || params[:unique]
    buffer = []
    ARGF.each_line do |line|
      buffer << line
    end
    tokenizer.tokenize buffer.join(' ')
  else
    ARGF.each_line do |line|
      tokenizer.tokenize line
    end
  end

rescue Tokenizer::Error => e
  $stderr.write "#{TOKENIZER_EXECUTABLE_NAME}: #{e.message}\n"
  exit TOKENIZER_ERROR_RUNTIME
end

